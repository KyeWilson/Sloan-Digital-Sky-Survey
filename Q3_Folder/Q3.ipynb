{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: How Does Choice of Activation Function Affect Neural Network Performance?\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this tutorial, we investigate how the choice of activation function impacts the performance of a Neural Network Classifier. Specifically, we will:\n",
    "\n",
    "- Compare three activation functions: ReLU, Sigmoid, and Tanh.\n",
    "\n",
    "- Evaluate their effect on model accuracy, loss, and generalisation.\n",
    "\n",
    "- Understand their practical implications in training neural networks.\n",
    "\n",
    "### What is an Activation Function?\n",
    "\n",
    "Activation functions determine the output of a neuron in a neural network by introducing non-linearity, enabling the network to learn complex patterns. Their choice directly impacts gradient flow, convergence speed, and overall model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Activation Functions:\n",
    "\n",
    "#### ReLU (Rectified Linear Unit):\n",
    "\n",
    "- **Behaviour**: Sets negative values to 0 and keeps positive values unchanged.\n",
    "\n",
    "- **Pros**: Computationally efficient; avoids vanishing gradients.\n",
    "\n",
    "- **Cons**: Suffers from the dying ReLU problem, where neurons can become inactive.\n",
    "\n",
    "#### Sigmoid:\n",
    "\n",
    "- **Behaviour**: Maps inputs to a range between 0 and 1.\n",
    "\n",
    "- **Pros**: Suitable for probabilities and output layers in binary classification.\n",
    "\n",
    "- **Cons**: Computationally expensive and prone to vanishing gradients for extreme input values.\n",
    "\n",
    "#### Tanh:\n",
    "\n",
    "- **Behaviour**: Maps inputs to a range between -1 and 1.\n",
    "\n",
    "- **Pros**: Zero-centred outputs improve convergence for some datasets.\n",
    "\n",
    "- **Cons**: Suffers from vanishing gradients for large inputs.\n",
    "\n",
    "### Methodology:\n",
    "\n",
    "We will evaluate these activation functions by training three identical neural networks, each using a different activation function in the hidden layers. Performance will be compared across metrics such as training accuracy, test accuracy, and generalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Preparing the Dataset\n",
    "\n",
    "Before training neural networks with different activation functions, we preprocess the Galaxy Zoo dataset to ensure it is ready for use. Proper preprocessing ensures the model learns effectively and avoids issues such as bias due to unscaled features.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Tasks to Complete**:\n",
    "\n",
    "1. **Normalise the Features**:\n",
    "\n",
    "   - Features such as `ra`, `dec`, and magnitudes (`u`, `g`, `r`, `i`, `z`, `redshift`) have different ranges.\n",
    "   \n",
    "   - For example:\n",
    "   \n",
    "     - Right Ascension (`ra`) might range from 0 to 360 degrees.\n",
    "     \n",
    "     - Magnitudes (`u`, `g`, etc.) could range from 14 to 30.\n",
    "     \n",
    "   - Steps for Normalisation:\n",
    "   \n",
    "     - Subtracting the mean of each feature.\n",
    "     \n",
    "     - Dividing by the standard deviation of the feature.\n",
    "     \n",
    "   **Why This Matters**:\n",
    "   \n",
    "     - Ensures all features contribute equally to the training process.\n",
    "       \n",
    "     - Prevents features with larger values (e.g., `ra`) from dominating those with smaller values (e.g., `z`).\n",
    "\n",
    "---\n",
    "\n",
    "2. **One-Hot Encode the Target Labels**:\n",
    "\n",
    "   - The `class` column contains categories: `Galaxy`, `Star`, and `Quasar`.\n",
    "   \n",
    "   - Neural Networks require numerical inputs, so we convert these categories into one-hot encoded arrays:\n",
    "     - Galaxy → [1, 0, 0]\n",
    "     - Star → [0, 1, 0]\n",
    "     - Quasar → [0, 0, 1]\n",
    "\n",
    "   **Steps for One-Hot Encoding**:\n",
    "   \n",
    "   - Identify all unique classes in the target column.\n",
    "   \n",
    "   - Assign each class to a unique numerical representation.\n",
    "   \n",
    "   - Convert these numerical representations into arrays.\n",
    "\n",
    "   **Why This Matters**:\n",
    "   \n",
    "   - Enables the neural network to handle multi-class classification.\n",
    "   \n",
    "   - Allows the output layer of the neural network to produce class probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Split the Dataset**:\n",
    "\n",
    "   - Divide the dataset into:\n",
    "   \n",
    "     - **Training Set**: 80% of the data for training the model.\n",
    "     \n",
    "     - **Test Set**: 20% of the data for evaluating the model.\n",
    "\n",
    "   **Why This Matters**:\n",
    "   \n",
    "   - Prevents overfitting by ensuring the model does not \"memorise\" the dataset.\n",
    "   \n",
    "   - Allows us to measure how well the model performs on new, unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Expected Outcome**:\n",
    "- The dataset is normalised (features scaled to a mean of 0 and standard deviation of 1).\n",
    "- The target labels are one-hot encoded (e.g., [1, 0, 0] for Galaxy).\n",
    "- The data is split into training and test sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Training Neural Networks with Different Activation Functions\n",
    "\n",
    "In this step, we will train three separate Neural Networks, each using a different activation function (**ReLU**, **Sigmoid**, and **Tanh**) in the hidden layers. This comparison will help us understand how these activation functions impact the model's ability to learn patterns in the Galaxy Zoo dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps to Follow**:\n",
    "\n",
    "1. **Define the Model Architecture**:\n",
    "\n",
    "All three models will share the same structure:\n",
    "\n",
    "   - **Input Layer**:\n",
    "   \n",
    "       - 8 neurons, one for each feature (`ra`, `dec`, `u`, `g`, `r`, `i`, `z`, `redshift`).\n",
    "       \n",
    "   - **Hidden Layers**:\n",
    "       \n",
    "       - 64 neurons in the first layer.\n",
    "         \n",
    "       - 32 neurons in the second layer.\n",
    "         \n",
    "       - Each model will use a different activation function (ReLU, Sigmoid, or Tanh) in the hidden layers.\n",
    "       \n",
    "   - **Output Layer**:\n",
    "   \n",
    "       - 3 neurons (one for each class: `Galaxy`, `Star`, `Quasar`).\n",
    "       \n",
    "       - Softmax activation function ensures the outputs represent probabilities.\n",
    "\n",
    "**Why Use This Architecture?**\n",
    "   \n",
    "   - The input layer matches the number of features in the dataset.\n",
    "   \n",
    "   - Two hidden layers provide sufficient capacity to learn complex relationships in the data.\n",
    "   \n",
    "   - The softmax output ensures the model predicts the probabilities of each class.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Compile the Model**:\n",
    "\n",
    "All three models will use the same optimiser, loss function, and metric for consistency:\n",
    "   \n",
    "   - **Optimiser**: Adam.\n",
    "     \n",
    "        - Adjusts the learning rate during training for better optimisation.\n",
    "       \n",
    "   - **Loss Function**: Categorical cross-entropy.\n",
    "     \n",
    "       - Suitable for multi-class classification tasks.\n",
    "       \n",
    "   - **Metric**: Accuracy.\n",
    "     \n",
    "       - Tracks the percentage of correct predictions during training.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Train Each Model**:\n",
    "\n",
    "Train each model on the **training dataset** for the same number of epochs (e.g., 20) and batch size (e.g., 32). Use the same **validation dataset** to monitor performance during training.\n",
    "\n",
    "   **Training Parameters**:\n",
    "   \n",
    "   - **Epochs**\n",
    "   \n",
    "       - Determines how many times the model sees the entire training dataset.\n",
    "   \n",
    "   - **Batch Size**\n",
    "   \n",
    "       - The number of samples the model processes before updating its parameters.\n",
    "\n",
    "   - **Why Train All Models the Same Way?**\n",
    "   \n",
    "       - Ensures a fair comparison by eliminating differences in training setup.\n",
    "\n",
    "---\n",
    "\n",
    "#### **What to Record**:\n",
    "\n",
    "1. **Training Metrics**:\n",
    "\n",
    "   - Track the accuracy and loss for each model during training.\n",
    "   \n",
    "   - Monitor how the metrics improve over epochs.\n",
    "\n",
    "2. **Validation Metrics**:\n",
    "\n",
    "   - Track the accuracy and loss on the validation dataset to assess generalisation.\n",
    "\n",
    "3. **Training Time**:\n",
    "\n",
    "   - Note the time taken to train each model, as some activation functions (e.g., Sigmoid) may be slower.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why This Step is Important**:\n",
    "- Activation functions play a critical role in determining how the Neural Network learns patterns.\n",
    "\n",
    "- Comparing training and validation metrics will reveal which activation function is more effective for this dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Expected Outcome**:\n",
    "- Three trained Neural Networks with recorded metrics for training and validation accuracy and loss. Plus the recorded training times for each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluating and Comparing Activation Functions\n",
    "\n",
    "After training the three Neural Networks, we evaluate their performance using the **test dataset** and compare the results. This step highlights how the choice of activation function impacts the model's ability to classify celestial objects.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Metrics to Evaluate**:\n",
    "\n",
    "1. **Accuracy**:\n",
    "\n",
    "   - Measures the percentage of correct predictions.\n",
    "   \n",
    "   - A higher accuracy indicates better overall performance.\n",
    "\n",
    "2. **Loss**:\n",
    "\n",
    "   - Represents how well the model fits the data.\n",
    "   \n",
    "   - Lower loss values indicate a better fit.\n",
    "\n",
    "3. **Precision**:\n",
    "\n",
    "   - The proportion of positive predictions that are correct for each class.\n",
    "   \n",
    "   - High precision means fewer false positives.\n",
    "\n",
    "4. **Recall**:\n",
    "\n",
    "   - The proportion of actual positives that are correctly predicted for each class.\n",
    "   \n",
    "   - High recall means fewer false negatives.\n",
    "\n",
    "5. **F1-Score**:\n",
    "\n",
    "   - A harmonic mean of precision and recall.\n",
    "   \n",
    "   - Useful for understanding performance on imbalanced datasets.\n",
    "\n",
    "6. **Confusion Matrix**:\n",
    "\n",
    "   - Provides a detailed breakdown of the predictions:\n",
    "   \n",
    "     - Rows represent actual classes.\n",
    "     \n",
    "     - Columns represent predicted classes.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Steps to Follow**:\n",
    "\n",
    "1. **Evaluate Each Model**:\n",
    "\n",
    "   - Use the test dataset to calculate accuracy, precision, recall, F1-score, and loss for each Neural Network (`ReLU`, `Sigmoid`, `Tanh`).\n",
    "\n",
    "2. **Generate Confusion Matrices**:\n",
    "\n",
    "   - Visualise the confusion matrix for each model to understand where it makes correct and incorrect predictions.\n",
    "\n",
    "3. **Compare Metrics**:\n",
    "\n",
    "   - Create a table to summarise the metrics for each activation function.\n",
    "   \n",
    "   - Highlight differences in performance between `ReLU`, `Sigmoid`, and `Tanh`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Results Summary**:\n",
    "\n",
    "| Metric                 | ReLU  | Sigmoid | Tanh  |\n",
    "|------------------------|-------|---------|-------|\n",
    "| **Accuracy**           | 0.98  | 0.96    | 0.98  |\n",
    "| **Precision (Galaxy)** | 0.97  | 0.94    | 0.97  |\n",
    "| **Recall (Galaxy)**    | 0.98  | 0.95    | 0.98  |\n",
    "| **Precision (Star)**   | 0.96  | 0.92    | 0.96  |\n",
    "| **Recall (Star)**      | 0.95  | 0.91    | 0.95  |\n",
    "| **Precision (Quasar)** | 0.99  | 0.95    | 0.99  |\n",
    "| **Recall (Quasar)**    | 0.99  | 0.94    | 0.99  |\n",
    "\n",
    "---\n",
    "\n",
    "#### **Observations**:\n",
    "\n",
    "1. **ReLU**:\n",
    "\n",
    "    - Achieved the highest accuracy and performed well across all classes.\n",
    "\n",
    "    - Fast to train and avoids vanishing gradient issues.\n",
    "\n",
    "2. **Sigmoid**:\n",
    "\n",
    "    - Slightly lower accuracy due to vanishing gradient problems during training.\n",
    "    \n",
    "    - Struggled with complex classifications, leading to lower precision and recall.\n",
    "\n",
    "3. **Tanh**:\n",
    "\n",
    "    - Performed as well as `ReLU`, with slightly lower loss values.\n",
    "\n",
    "    - Suitable for datasets with features that benefit from zero-centred outputs.\n",
    "\n",
    "4. **Generalisation**:\n",
    "\n",
    "    - Both `ReLU` and `Tanh` generalised well to the test dataset, with minimal overfitting.\n",
    "    \n",
    "    - `Sigmoid` showed signs of slower learning, leading to lower overall performance.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why These Metrics Matter**:\n",
    "\n",
    "1. **Accuracy**: Provides a broad view of model performance but doesn’t reveal class-specific details.\n",
    "\n",
    "2. **Precision and Recall**: Offer insight into how well the model handles individual classes (e.g., `Galaxy`, `Star`, `Quasar`).\n",
    "\n",
    "3. **F1-Score**: Balances precision and recall, especially for imbalanced datasets like Galaxy Zoo.\n",
    "\n",
    "4. **Confusion Matrices**: Reveal specific misclassifications, helping to diagnose model weaknesses.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Expected Outcome**:\n",
    "\n",
    "1. A comprehensive comparison of the three Neural Networks (`ReLU`, `Sigmoid`, `Tanh`).\n",
    "\n",
    "2. Clear visualisations (line plots and confusion matrices) highlighting differences in performance.\n",
    "\n",
    "3. Insights into why certain activation functions performed better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Conclusion\n",
    "\n",
    "In this final step, we summarise the results of our investigation into how the choice of activation function impacts the performance of a Neural Network Classifier. We discuss key findings, provide actionable insights, and identify when each activation function might be most appropriate.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Findings**\n",
    "\n",
    "1. **Performance Across Activation Functions**:\n",
    "\n",
    "   - `ReLU` and `Tanh` achieved the highest accuracy (0.98), demonstrating their effectiveness for this dataset.\n",
    "   \n",
    "   - `Sigmoid` lagged behind with lower accuracy (0.96), likely due to vanishing gradient issues during training.\n",
    "\n",
    "2. **Class-Specific Observations**:\n",
    "\n",
    "   - Both `ReLU` and `Tanh` handled the classification of all object types (`Galaxy`, `Star`, `Quasar`) effectively, with high precision and recall.\n",
    "   \n",
    "   - `Sigmoid` struggled with more complex classifications (e.g `Quasars`), leading to reduced precision and recall.\n",
    "\n",
    "3. **Training Efficiency**:\n",
    "\n",
    "   - `ReLU` trained faster due to its simplicity and efficiency in handling gradients.\n",
    "   \n",
    "   - `Sigmoid` required more time due to slower convergence.\n",
    "   \n",
    "   - `Tanh` performed comparably to ReLU in training speed.\n",
    "\n",
    "4. **Generalisation**:\n",
    "\n",
    "   - Both `ReLU` and `Tanh` generalised well to the test dataset, indicating minimal overfitting.\n",
    "   \n",
    "   - `Sigmoid` showed signs of slower learning, leading to suboptimal generalisation.\n",
    "\n",
    "---\n",
    "\n",
    "#### **When to Use Each Activation Function**\n",
    "\n",
    "1. **ReLU**:\n",
    "\n",
    "   - Best for hidden layers in most Neural Network architectures.\n",
    "   \n",
    "   - Avoids vanishing gradients, leading to faster and more efficient training.\n",
    "   \n",
    "   - Suitable for large and complex datasets like Galaxy Zoo.\n",
    "\n",
    "2. **Tanh**:\n",
    "\n",
    "   - A strong alternative to `ReLU`, particularly for datasets that benefit from zero-centred outputs.\n",
    "   \n",
    "   - May slightly outperform `ReLU` in terms of loss reduction for specific datasets.\n",
    "\n",
    "3. **Sigmoid**:\n",
    "\n",
    "   - Useful for binary classification tasks or when probabilities are required in the output layer.\n",
    "   \n",
    "   - Generally not recommended for hidden layers due to vanishing gradient problems.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Final Recommendations**\n",
    "\n",
    "For the Galaxy Zoo dataset, `ReLU` is the most suitable activation function due to its high accuracy, fast training, and ability to generalise well to unseen data. `Tanh` is a strong alternative, particularly for applications where zero-centred outputs are preferred. `Sigmoid` should be avoided in this context as it underperformed compared to the other two.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Summary of Results**\n",
    "\n",
    "| Activation Function | Accuracy | Training Speed | Generalisation | Recommended For                 |\n",
    "|---------------------|----------|----------------|----------------|---------------------------------|\n",
    "| **ReLU**            | 0.98     | Fast           | Excellent      | Large, complex datasets         |\n",
    "| **Tanh**            | 0.98     | Moderate       | Excellent      | Zero-centred data, smaller tasks|\n",
    "| **Sigmoid**         | 0.96     | Slow           | Moderate       | Binary classification tasks     |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
